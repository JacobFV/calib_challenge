{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjPMV_oOq0nw",
        "outputId": "02e7961e-e28d-47f5-f927-049ae6acb905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'calib_challenge'...\n",
            "remote: Enumerating objects: 80, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 80 (delta 17), reused 23 (delta 15), pack-reused 51\u001b[K\n",
            "Receiving objects: 100% (80/80), 358.09 MiB | 16.38 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/JacobFV/calib_challenge"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd calib_challenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeOaiO2Q1TYx",
        "outputId": "3b8f71db-b502-4f7e-ed80-31ace527015f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/calib_challenge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git rm commavq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnG7vPPCr7ZN",
        "outputId": "5ee09162-f633-447d-866e-dec7cd062d25"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm 'commavq'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git submodule add https://github.com/commaai/commavq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4cMu0jzrdH1",
        "outputId": "0ff0d922-7989-4ae8-e04a-f916ebbe02c0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/calib_challenge/commavq'...\n",
            "remote: Enumerating objects: 173, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 173 (delta 41), reused 61 (delta 32), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (173/173), 78.60 MiB | 10.84 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install einops torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Yxbe2T13sHS1",
        "outputId": "9cbe0c02-4844-44ae-c4fb-c00853c09863"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python notebook.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JaITHTUsCxp",
        "outputId": "f0d43a5a-38c9-4b6d-9dc2-611905bb95a9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/calib_challenge/notebook.py\", line 78, in <module>\n",
            "    train_loader = load_ds()\n",
            "  File \"/content/calib_challenge/notebook.py\", line 54, in load_ds\n",
            "    video_frames = extract_frames(f\"labeled/{i}.hevc\")\n",
            "  File \"/content/calib_challenge/notebook.py\", line 38, in extract_frames\n",
            "    ret, frame = cap.read()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Adjust the import paths for custom modules\n",
        "from commavq.utils.vqvae import Encoder, CompressorConfig"
      ],
      "metadata": {
        "id": "8UXF7FB3EcN4"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple two-layer MLP with integrated Encoder\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, encoder):\n",
        "        super(MLP, self).__init__()\n",
        "        self.encoder = encoder  # Pretrained encoder\n",
        "        self.layer1 = nn.Linear(input_dim, 128)  # First hidden layer\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer2_res = nn.Linear(128, 128)  # Residual stream\n",
        "        self.layer2_relu = nn.Linear(128, 128)  # ReLU stream\n",
        "        self.merge = nn.Linear(256, 128)  # Merge layer\n",
        "        self.downproject = nn.Linear(128, output_dim)  # Downproject layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            x = self.encoder(x)\n",
        "            x = x.float() / config.vocab_size  # Normalize encoder output\n",
        "        x = self.layer1(x)\n",
        "        x_res = self.layer2_res(x)\n",
        "        x_relu = self.relu(self.layer2_relu(x))\n",
        "        x_merged = torch.cat((x_res, x_relu), dim=1)\n",
        "        x_merged = self.merge(x_merged)\n",
        "        x = self.downproject(x_merged)\n",
        "        return x"
      ],
      "metadata": {
        "id": "B1gV5BzwEcGX"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_frames(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.resize(frame, (224, 224))\n",
        "        frame = frame / 255.0\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "    frames = np.array(frames)\n",
        "    frames = frames.transpose((0, 3, 1, 2))  # Change from B H W C to B C H W\n",
        "    return frames\n",
        "\n",
        "def load_ds():\n",
        "    # Load all labeled data\n",
        "    all_frames = []\n",
        "    all_angles = []\n",
        "    for i in range(5):  # Assuming 5 labeled videos (0.hevc to 4.hevc)\n",
        "        video_frames = extract_frames(f\"labeled/{i}.hevc\")\n",
        "        angles = np.loadtxt(f\"labeled/{i}.txt\")\n",
        "        assert len(video_frames) == len(angles), f\"Mismatch in frames and angles count for video {i}!\"\n",
        "        all_frames.append(video_frames)\n",
        "        all_angles.append(angles)\n",
        "\n",
        "    # Concatenate all data\n",
        "    X = np.concatenate(all_frames, axis=0)\n",
        "    y = np.concatenate(all_angles, axis=0)\n",
        "\n",
        "    # Remove samples where speed is less than 4m/s (NaN values)\n",
        "    valid_indices = ~np.isnan(y).any(axis=1)\n",
        "    X = X[valid_indices]\n",
        "    y = y[valid_indices]\n",
        "\n",
        "    # Create TensorDataset\n",
        "    train_tensor = TensorDataset(\n",
        "        torch.tensor(X, dtype=torch.float32),\n",
        "        torch.tensor(y, dtype=torch.float32),\n",
        "    )\n",
        "    train_loader = DataLoader(train_tensor, batch_size=64, shuffle=True)\n",
        "    return train_loader"
      ],
      "metadata": {
        "id": "XQaIcqyrEb95"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_loader = load_ds()\n",
        "\n",
        "DEVICE_NAME = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load and configure the encoder\n",
        "config = CompressorConfig()\n",
        "encoder = Encoder(config)\n",
        "encoder.load_state_dict_from_url(\n",
        "    \"https://huggingface.co/commaai/commavq-gpt2m/resolve/main/encoder_pytorch_model.bin\",\n",
        "    assign=True,\n",
        ")\n",
        "encoder = encoder.eval().to(device=DEVICE_NAME)\n",
        "\n",
        "# Initialize the Predictor with the correct dimensions and integrated encoder\n",
        "predictor = MLP(input_dim=196, output_dim=2, encoder=encoder).to(DEVICE_NAME)\n",
        "\n",
        "# Training loop\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(predictor.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10  # You can adjust this"
      ],
      "metadata": {
        "id": "YoDc9PIGEb19"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs = inputs.to(DEVICE_NAME)\n",
        "        targets = targets.to(DEVICE_NAME)\n",
        "        predictions = predictor(inputs)\n",
        "        loss = criterion(predictions, targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.8f}\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(predictor.state_dict(), \"predictor_model.pth\")\n",
        "\n",
        "print(\"Training completed and model saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XUocx56EbuK",
        "outputId": "ff9ff7cf-4ae6-4287-9752-74c3392bfd5b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Average Loss: 0.0005\n",
            "Epoch 2/10, Average Loss: 0.0001\n",
            "Epoch 3/10, Average Loss: 0.0001\n",
            "Epoch 4/10, Average Loss: 0.0000\n",
            "Epoch 5/10, Average Loss: 0.0000\n",
            "Epoch 6/10, Average Loss: 0.0000\n",
            "Epoch 7/10, Average Loss: 0.0000\n",
            "Epoch 8/10, Average Loss: 0.0000\n",
            "Epoch 9/10, Average Loss: 0.0000\n",
            "Epoch 10/10, Average Loss: 0.0000\n",
            "Training completed and model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "predictor.load_state_dict(torch.load(\"predictor_model.pth\"))\n",
        "predictor.eval()\n",
        "\n",
        "def process_unlabeled_videos(model, device):\n",
        "    for i in range(5, 10):  # Unlabeled videos are 5.hevc to 9.hevc\n",
        "        video_frames = extract_frames(f\"unlabeled/{i}.hevc\")\n",
        "        predictions = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for frame in video_frames:\n",
        "                frame_tensor = torch.tensor(frame[np.newaxis, ...], dtype=torch.float32).to(device)\n",
        "                pred = model(frame_tensor).cpu().numpy()[0]\n",
        "                predictions.append(pred)\n",
        "\n",
        "        predictions = np.array(predictions)\n",
        "\n",
        "        # Save predictions\n",
        "        np.savetxt(f\"{i}.txt\", predictions, fmt='%.18e')\n",
        "\n",
        "    print(\"Predictions for unlabeled videos generated and saved.\")\n",
        "\n",
        "# Process unlabeled videos and generate predictions\n",
        "process_unlabeled_videos(predictor, DEVICE_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn0mKfJbEZvi",
        "outputId": "4a9ef29c-d5a0-4dd7-b128-59dcbd16ce2f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for unlabeled videos generated and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval.py unlabeled/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2POVKBuLGDsy",
        "outputId": "5d74d4df-4209-4fa9-e190-e03573090b35"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/calib_challenge/eval.py\", line 23, in <module>\n",
            "    test = np.loadtxt(TEST_DIR + str(i) + '.txt')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\", line 1373, in loadtxt\n",
            "    arr = _read(fname, dtype=dtype, comment=comment, delimiter=delimiter,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\", line 992, in _read\n",
            "    fh = np.lib._datasource.open(fname, 'rt', encoding=encoding)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/_datasource.py\", line 193, in open\n",
            "    return ds.open(path, mode, encoding=encoding, newline=newline)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/_datasource.py\", line 533, in open\n",
            "    raise FileNotFoundError(f\"{path} not found.\")\n",
            "FileNotFoundError: unlabeled/0.txt not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: zip labels/* into labels.zip\n",
        "\n",
        "!zip -r labels.zip labels/*\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUox7UzHH2KK",
        "outputId": "b50d03ee-c407-4841-d05b-771d35bd696f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: labels/5.txt (deflated 87%)\n",
            "  adding: labels/6.txt (deflated 75%)\n",
            "  adding: labels/7.txt (deflated 60%)\n",
            "  adding: labels/8.txt (deflated 90%)\n",
            "  adding: labels/9.txt (deflated 63%)\n"
          ]
        }
      ]
    }
  ]
}